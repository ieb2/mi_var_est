---
title: "main_doc"
author: "Ihsan E. Buker"
date: "`r Sys.Date()`"
output: html_document
---
# Dependencies 
```{r}
library(tidyverse)
library(magrittr)
library(mice)
library(MASS)

library(boot)
library(rsample) # rsample might give more flexibility with mids. 
```

# Toy Example 
```{r, cache=T}
set.seed(971423)

cor_mat <- matrix(c(1, 0.5, 0.5, 
                    0.5, 1, 0.5, 
                    0.5, 0.5, 1), nrow = 3, ncol = 3)

mean_vec <- c(1, 5, 10)

data_complete <- mvrnorm(100, mu = mean_vec, Sigma = cor_mat)

data_w_missing <- ampute(data_complete, prop = 0.3, mech = "MAR", patterns = c(0, 1, 1))$amp

# V1 is an outcome variable with 30% MAR. Covariates are fully observed. 

# The analysis model is V1 ~ V2 + V3 + epsilon 
# We are interested in estimating var(beta*V2)

# Congenial imputation model 
congenial_imputation_model <- make.predictorMatrix(data_w_missing) %>%
  as.matrix()

# Uncongenial imputation model 
uncongenial_imputation_model <- make.predictorMatrix(data_w_missing) %>%
  as.matrix()

uncongenial_imputation_model[1, ] <- c(0,1,0)

# Congenial imputation 
con_imp <- mice(data_w_missing, method = "pmm", predictorMatrix = congenial_imputation_model)

# Uncongenial imputation 
uncon_imp <- mice(data_w_missing, method = "pmm", predictorMatrix = uncongenial_imputation_model)

# Fitting analysis model 

# Rubin's rules 
# var(beta*V2) = 0.02020468 -> Our reference value. 
con_model <- with(con_imp, lm(V1 ~ V2 + V3)) %>%
  pool() %>%
  summary() %>%
  mutate(variance = std.error^2)

# var(beta*V2) = 0.01320681
uncon_model <- with(uncon_imp, lm(V1 ~ V2 + V3)) %>%
  pool() %>%
  summary() %>%
  mutate(variance = std.error^2)

# MI boot Rubin 
bootstrap_samples_V2 <- map(complete(uncon_imp, "long") %>%
      group_split(.imp), ~bootstraps(., 
                                    times = 1E1, 
                                    apparent = FALSE) %>% 
      mutate(model = map(splits, ~lm(V1 ~ V2 + V3, data = .)), 
             coef_inf = map(model, tidy)))

coef_extractor <- function(x){
  model_coefs <- x %>%
    unnest(coef_inf) %>%
    filter(term == "V2") %>%
    mutate(variance = std.error ^ 2)
  
  return(model_coefs)
}

model_coefs_V2 <- map(bootstrap_samples_V2, coef_extractor)

# mean var(V2) = 0.01062996
m_mean_vars <- sapply(model_coefs_V2, function(x) mean(x$variance)) 

model_coefs_V2_x <- mapply(cbind, model_coefs_V2, "m_mean_var" = m_mean_vars, SIMPLIFY = F)

var_calc <- function(x){
  x %>%
  dplyr::mutate("internal_argument" = (variance - m_mean_vars)^2)
}

model_coefs_V2_z <- map(model_coefs_V2_x, var_calc)

ID <- c(1,2,3,4,5)

model_coefs_V2_final <- mapply(cbind, model_coefs_V2_z, "SampleID"=ID, SIMPLIFY=F)

flat_list <- bind_rows(model_coefs_V2_final)

flat_list %>%
  ggplot(aes(
    x = variance,
    y = ..scaled..,
    color = as.factor(SampleID),
    fill = as.factor(SampleID)
  )) +
  geom_density(alpha = .3) +
  ggtitle("Distribution of Estimated Variance of B_{V2}") +
  xlab("Estimate") +
  ylab("Frequency") +
  theme_minimal() +
  theme(legend.title = element_blank())

# stat_function(fun = dnorm,
#                 args = list(mean = mean(model_coefs_V2[[1]]$variance),
#                             sd = sd(model_coefs_V2[[1]]$variance)),
#                 col = "#1b98e0",
#                 size = 2)



p <- flat_list %>%
  dplyr::select(SampleID, internal_argument) %>%
  group_split(SampleID) 

lapply(p, function(x) sum(x$internal_argument)/99)
```

# Current Questions 

  * Authors compare all methods to the $var(\beta_{V2})$ estimated by the congenial imputation model and Rubin's rules for variance. Since data is simulated, could we not compare all methods to the $var(\beta_{V2})$ obtained by fitting the analysis model to the complete dataset (prior to amputation). 