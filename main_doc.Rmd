---
title: "main_doc"
author: "Ihsan E. Buker"
date: "`r Sys.Date()`"
output: html_document
---
# Updates 

# Dependencies 
```{r}
library(tidyverse)
library(magrittr)
library(mice)
library(MASS)
library(sjPlot)
library(sjmisc)
library(ggplot2)

library(boot)
library(rsample)
```

# Toy Example 
```{r, cache=T}
set.seed(971423)

cor_mat <- matrix(c(1, 0.5, 0.5, 
                    0.5, 1, 0.5, 
                    0.5, 0.5, 1), nrow = 3, ncol = 3)

mean_vec <- c(1, 1, 1)

covariates <- as.data.frame(mvrnorm(100, mu = mean_vec, Sigma = cor_mat))
covariates$V3 <- ifelse(covariates$V3 > 0, 1, 0)

outcome_variable <- 0 + 
  0.32*covariates$V1 + 
  0.67*covariates$V2 +  
  0.43*covariates$V3 + 
  0.50*covariates$V2*covariates$V3 + # Interaction btwn. V2&V3
  rnorm(100,0,1)

data_complete <- cbind(outcome_variable, covariates)
data_complete$V3 <- as.factor(data_complete$V3)

fit <- lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = data_complete)
summary(fit)

# The influence of V2 on outcome var is different for values of V3
# Two-way interaction btwn. V2*V3. 
plot_model(fit, type = "int")

data_w_missing <- ampute(data_complete, prop = 0.3, mech = "MAR", patterns = c(0, 1, 1, 1))$amp

data_w_missing$V3 <- as.factor(ifelse(data_w_missing$V3 == 1, 0, 1))

# "outcome_variable" is an outcome variable with 30% MAR. Covariates are fully observed. 

# The analysis model is outcome_variable ~ V1 + V2 + V3
# We are interested in estimating var(beta*V2)
```

```{r}
# Congenial imputation 
part_one_con_imp <- 
  data_w_missing %>% 
  dplyr::filter(V3 == "0") %>%
  mice(., method = "pmm")

part_two_con_imp <- 
  data_w_missing %>% 
  dplyr::filter(V3 == "1") %>%
  mice(., method = "pmm")

con_imp_data <- rbind(
  complete(part_one_con_imp, "long"),
  complete(part_two_con_imp, "long")
)
# Uncongenial imputation 
uncon_imp <- mice(data_w_missing, method = "pmm")

uncon_imp_data <- complete(uncon_imp, "long")

# Fitting analysis model 

# Rubin's rules 
# var(beta*V2) = 0.02430348 -> Our reference value. 
con_imp_data %>%
  by(as.factor(.$.imp), lm, formula = outcome_variable ~ V1 + V2 + V3 +  V2*V3) %>%
  pool() %>%
  summary() %>%
  mutate(variance = std.error^2) 

# var(beta*V2) = 0.03304946
uncon_imp_data %>%
  by(as.factor(.$.imp), lm, formula = outcome_variable ~ V1 + V2 + V3 +  V2*V3) %>%
  pool() %>%
  summary() %>%
  mutate(variance = std.error^2) 

# MI boot Rubin 
times = 1E2
bootstrap_samples <- map(
  uncon_imp_data %>%
    group_split(.imp),
  ~ bootstraps(.,
               times = times,
               apparent = FALSE) %>%
    mutate(
      model = map(splits, ~ lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = .)),
      coef_inf = map(model, tidy)
    )
)

# Function to obtain the statistics associated with term==V2, and calculate var.  
coef_extractor <- function(x){
  model_coefs <- x %>%
    unnest(coef_inf) %>%
    filter(term == "V2") %>%
    mutate(variance = std.error ^ 2)
  
  return(model_coefs)
}

model_coefs <- map(bootstrap_samples, coef_extractor)

m_mean_vars <- sapply(model_coefs, function(x) mean(x$variance)) 

model_coefs_w_mean <- mapply(cbind, model_coefs, "m_mean_var" = m_mean_vars, SIMPLIFY = F)

# Function to calculate numerator of the variance formula 
var_calc <- function(x){
  x %>%
    dplyr::mutate("internal_argument" = ({variance - m_mean_vars})^2)
}

model_coefs_w_numerator <- map(model_coefs_w_mean, var_calc)

ID <- c(1:(uncon_imp$m))

model_coefs_final <- mapply(cbind, model_coefs_w_numerator, "SampleID"=ID, SIMPLIFY=F)

flat_list <- bind_rows(model_coefs_final)

Vw <- sum(unlist(as.vector(flat_list %>%
                       dplyr::select(variance)))) / 999

Vb <- sum(unlist(as.vector(flat_list %>%
  dplyr::select(internal_argument)))) / {uncon_imp$m-1}

Vtotal <- Vw + Vb + Vb/{uncon_imp$m-1}
  

flat_list %>%
  ggplot(aes(
    x = variance,
    y = ..scaled..,
    color = as.factor(SampleID),
    fill = as.factor(SampleID)
  )) +
  geom_density(alpha = .3) +
  ggtitle(paste("Distribution of Estimated Variance of B_{V2}: B =", times, sep = "")) +
  xlab("Estimate") +
  ylab("Frequency") +
  theme_minimal() +
  theme(legend.title = element_blank())

p <- flat_list %>%
  dplyr::select(SampleID, internal_argument) %>%
  group_split(SampleID) 


sapply(p, function(x) sum(x$internal_argument)) %>%
  mean()

# MI boot pooled percentile
se <- function(x) sqrt(var(x) / length(x))

# var(theta_2) = 0.009357518
var_est_theta_2 <- sapply(p, function(x) sum(x$internal_argument)) %>%
  mean()

# se(theta_2) = 0.001376763
se_theta_2 <- sapply(p, function(x) sum(x$internal_argument)) %>%
  se()

UB <- var_est_theta_2 + 1.96*se_theta_2
LB <- var_est_theta_2 - 1.96*se_theta_2

print(c(UB, LB))

# Boot MI percentile

# 1) B bootstraps are generated from the observed data. 
# 2) Each of the b=1...B datasets are imputed M times. 
# 3) Rubin's rules are used to obtain point estimates of theta
# 4) Bootstrap confidence interval of the estimator is obtained
library(bootImpute)

boot_impute <- bootMice(data_w_missing, nBoot = 100, nImp = 2, nCores = 4, seed = 971423)

x <- map(boot_impute, ~tidy(lm(V1 ~ V2 + V3, data = .)))

res <- c()
for(i in 1:length(x)){
  res[[i]] <- x[[i]] %>%
  dplyr::filter(term=="V2") %>%
  mutate(variance = std.error^2)
}

flat_models <- bind_rows(res, .id = "column_label")

flat_models$variance %>%
  mean()

lm(V1 ~ V2 + V3, data = as.data.frame(data_complete)) %>%
  summary()
```

# Rubin's method with the uncongenial imputation model is more accurate than with the congenial imputation model, how? 

# 