---
title: "main_doc"
author: "Ihsan E. Buker"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---
# Updates 
  
  * Had to change sizes: 
    * N = 333 vs. 999 
    * B = 5 vs. 200 
    * m = 5 vs. 10 
    * itr = 5 vs. ~25
  * Problem with rlang on server but think I got it figured out. 
  * Need to organize data
    * Combine point estimates and CIs 
    * Literature focuses on CI comparison 
  * Random question
    * 
# Dependencies 
```{r}
library(tidyverse)
library(magrittr)
library(mice)
library(MASS)
library(sjPlot) # Used for interaction visual 
library(sjmisc) # Used for interaction visual 
library(ggplot2) # Used for interaction visual 
library(furrr) # To use parallel "purrr" functions
library(progressr) # For progress bar on furrr 

library(rsample)
library(bootImpute) # For boot_mi_percentile 
```

# Data Generation 
```{r}
data_generator <- function(sample_size, prop, seed){
  set.seed(seed)
  cor_mat <- matrix(c(1, 0.5, 0.5, 
                      0.5, 1, 0.5, 
                      0.5, 0.5, 1), nrow = 3, ncol = 3)
  
  mean_vec <- c(1, 1, 1)
  
  covariates <- as.data.frame(mvrnorm(sample_size, mu = mean_vec, Sigma = cor_mat))
  covariates$V3 <- ifelse(covariates$V3 > 0, 1, 0)
  
  outcome_variable <- 0 + 
    0.32*covariates$V1 + 
    0.67*covariates$V2 +  
    0.43*covariates$V3 + 
    0.50*covariates$V2*covariates$V3 + # Interaction btwn. V2&V3
    rnorm(100,0,1)
  
  data_complete <- cbind(outcome_variable, covariates)
  data_complete$V3 <- as.factor(data_complete$V3)
  
  data_w_missing <- ampute(data_complete, prop = prop, mech = "MAR", patterns = c(0, 1, 1, 1))$amp
  
  data_w_missing$V3 <- as.factor(ifelse(data_w_missing$V3 == 1, 0, 1))
  
  # "outcome_variable" is an outcome variable with 30% MAR. Covariates are fully observed. 
  
  # The analysis model is outcome_variable ~ V1 + V2 + V3 + V2*V3 + epsilon 
  # We are interested in estimating var(beta*V2)
  
  return(data_w_missing)
}

# The influence of V2 on outcome var is different for values of V3
# Two-way interaction btwn. V2*V3. 
```

# Imputation of data
```{r, eval=FALSE}
# Congenial imputation 
# To accomodate interaction V3 == 0 and V3 == 1 are imputed independently and combined. See van Buuren "Derived Vars" 

part_one_con_imp <- 
  data_w_missing %>% 
  dplyr::filter(V3 == "0") %>%
  mice(., method = "pmm")

part_two_con_imp <- 
  data_w_missing %>% 
  dplyr::filter(V3 == "1") %>%
  mice(., method = "pmm")

con_imp <- mice::rbind(part_one_con_imp, part_two_con_imp) 
con_imp_data <- complete(con_imp, "long")

# Uncongenal imputation 
# Ignores interaction between V2:V3, uncongenial to analysis model which does not ignore interaction. 
uncon_imp <- mice(data_w_missing, method = "pmm")
uncon_imp_data <- complete(uncon_imp, "long")
```

# Full data analysis 
```{r, eval = FALSE}
# Fitting analysis model 
lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = data_complete) %>% 
  summary() %>%
  broom::tidy() %>%
  dplyr::filter(term == "V2") %>%
  dplyr::mutate(variance = {std.error*{sample_size^{1/2}}}^2)
```


# Simulation Setup 
* N = 999 datasets 
* p_mis $\in$ {0.10, 0.30, 0.50}
* Mechanism of Missingness = MAR 
* n = sample size $\in$ {500, 1000, 10000}
* q = number of covariates = 3 
* Interaction between Var2 and Var3 
```{r, warning=F, cache=FALSE}
set.seed(971423)
N = 333 
p_mis_vec <- c(rep(0.10, N), rep(0.30, N), rep(0.50, N))
sample_size_vec <- c(rep(500, N/3), rep(1000, N/3), rep(10000, N/3))
seed_vec <- rnorm(N, 0, 1)^2

sample_size_vec_repeated <- rep.int(sample_size_vec, 3)

param_df <- data.frame(sample_size = sample_size_vec_repeated, prop = p_mis_vec, seed = seed_vec)

data_frames <- do.call(Map, c(f=data_generator, param_df))

# Uncongenial Imputation of data frames w/ missing outcome_vars 
plan(multisession, workers = parallel::detectCores()-1)

with_progress({
  p <- progressor(steps = length(data_frames))
  
  uncon_imputed_data_frames <- future_map(data_frames, ~{
    p(); 
    mice(data = .x, method = "pmm", print=FALSE)
  }, p = p)
})

part_one_con_imp <-
  purrr::map(data_frames, ~ dplyr::filter(., V3 == "0"))

part_one_imputed <- lapply(part_one_con_imp, function(x) mice(x, method = "pmm", print = FALSE)) 

part_two_con_imp <-
  purrr::map(data_frames, ~ dplyr::filter(., V3 == "1"))

part_two_imputed <- lapply(part_two_con_imp, function(x) mice(x, method = "pmm", print = FALSE)) 

con_imputed_data_frames <- c()
for(i in 1:length(part_two_imputed)){
  con_imputed_data_frames[[i]] <- mice::rbind(part_one_imputed[[i]], part_two_imputed[[i]]) 
}
```

# Rubin's rules 
```{r}
rubin_results_uncongenial <- c()
for(i in 1:length(uncon_imputed_data_frames)){
  sample_size <- nrow(complete(uncon_imputed_data_frames[[i]],1))
  rubin_results_uncongenial[[i]] <- uncon_imputed_data_frames[[i]] %>%
    complete(., "long") %>%
    by(as.factor(.$.imp), lm, formula = outcome_variable ~ V1 + V2 + V3 +  V2*V3) %>%
    pool() %>%
    summary() %>%
    dplyr::mutate(variance = {std.error*{sample_size^{1/2}}}^2)
}

rubin_results_congenial <- c()

for(i in 1:length(con_imputed_data_frames)){
 sample_size <- nrow(complete(con_imputed_data_frames[[i]],1))
  rubin_results_congenial[[i]] <- try(con_imputed_data_frames[[i]] %>%
    complete(., "long") %>%
    by(as.factor(.$.imp), lm, formula = outcome_variable ~ V1 + V2 + V3 +  V2*V3) %>%
    pool() %>%
    summary() %>%
    dplyr::mutate(variance = {std.error*{sample_size^{1/2}}}^2))
}
```

## Confidence Interval for Rubin's method 
```{r}
ci_calc <- function(sample_size, variance, seed){
  set.seed(seed)
  denominator_l_b <- qchisq(.975, df={sample_size-1}, lower.tail = TRUE)
  numerator_l_b <- (sample_size-1)*variance
  LB <- {numerator_l_b/denominator_l_b}
  
  denominator_u_b <- qchisq(.025, df={sample_size-1}, lower.tail = TRUE)
  numerator_u_b <- (sample_size-1)*variance
  UB <- {numerator_u_b/denominator_u_b}
  
  variance <- variance 
  
  return(data.frame(UB,LB,variance))
}

uncongenial_vars_rubin <- vector("list", length = length(data_frames))
for(i in 1:length(data_frames)){
  uncongenial_vars_rubin[[i]] <- rubin_results_uncongenial[[i]] %>%
  dplyr::filter(term == "V2") %>%
  dplyr::select(variance)
}

congenial_vars_rubin <- vector("list", length = length(data_frames))
for(i in 1:length(data_frames)){
  congenial_vars_rubin[[i]] <- rubin_results_congenial[[i]] %>%
  dplyr::filter(term == "V2") %>%
  dplyr::select(variance)
}

ss_vec <- as.vector(unlist(param_df$sample_size))

var_vec <- as.vector(unlist(congenial_vars_rubin))

seeds <- as.vector(unlist(param_df$seed))

rubin_congenial_results_final <- vector("list", length = length(data_frames))
for(i in 1:length(data_frames)){
  rubin_congenial_results_final[[i]] <- 
    ci_calc(ss_vec[[i]], var_vec[[i]], seeds[[i]])
}

uncon_var_vec <- as.vector(unlist(uncongenial_vars_rubin))
rubin_uncongenial_results_final <- vector("list", length = length(data_frames))
for(i in 1:length(data_frames)){
  rubin_uncongenial_results_final[[i]] <- 
    ci_calc(ss_vec[[i]], uncon_var_vec[[i]], seeds[[i]])
}
```


# MI boot Rubin 
```{r}
mi_boot_rubin <- function(uncon_imp_data, seed, times){
  
  set.seed(seed)
  times = times # Number of bootstrap samples per m. 
  
  bootstrap_samples <- map(
    uncon_imp_data %>%
      complete(., "long") %>%
      group_split(.imp),
    ~ bootstraps(.,
                 times = times,
                 apparent = FALSE) %>%
      mutate(
        model = map(splits, ~ lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = .)),
        coef_inf = map(model, tidy)
      )
  )
  
  sample_size <- nrow(complete(uncon_imp_data, 1))
  
  # Function to obtain the statistics associated with term==V2, and calculate var.  
  coef_extractor <- function(x){
    model_coefs <- x %>%
      unnest(coef_inf) %>%
      filter(term == "V2") %>%
      dplyr::mutate(variance = {std.error*{sample_size^{1/2}}}^2)
    
    return(model_coefs)
  }
  
  # Obtains statistics associated with term == V2 
  model_coefs <- map(bootstrap_samples, coef_extractor)
  
  # Calculates mean var(Beta*V2) for m^th dataset. 
  m_mean_vars <- sapply(model_coefs, function(x) mean(x$variance)) 
  
  # Combines statistics w/ mean var(Beta*V2) of m^th dataset. 
  model_coefs_w_mean <- mapply(cbind, model_coefs, "m_mean_var" = m_mean_vars, SIMPLIFY = F)
  
  # Function to calculate the squared difference between m^th mean_var
  # and b^th var.  
  dif_calc <- function(x){
    x %>%
      dplyr::mutate("internal_argument" = ({variance - m_mean_vars})^2)
  }
  
  # Combines squared variance difference with rest of statistics. 
  model_coefs_w_ia <- map(model_coefs_w_mean, dif_calc)
  
  # Function to estimate within-imputation variance
  w_i_var_estimator <- function(x){
    data <- x$internal_argument
    var_est <- sum(data)/{times-1}
  }
  
  # Obtains M estimates of var(beta*V2) in list (Serves as ~Standard Error)
  var_se_estimate <- lapply(model_coefs_w_ia, w_i_var_estimator)
  
  # M point estimates of var(beta*V2) obtained from imputed but not 
  # bootstrapped data 
  
  var_point_estimate <- c()
  for(i in 1:uncon_imp_data$m){
    var_point_estimate[[i]] <- complete(uncon_imp_data, i) %>%
      lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = .) %>%
      summary() %>%
      broom::tidy() %>%
      dplyr::filter(term == "V2") %>%
      dplyr::mutate(variance = {std.error*{sample_size^{1/2}}}^2) %>%
      dplyr::select(variance)
  }
  
  sample_mean <- mean(as.data.frame(unlist(var_point_estimate))$"unlist(var_point_estimate)")
  conf_z_value <- 1.96 
  sample_sd <- mean({unlist(var_se_estimate)^{1/2}})/{uncon_imp_data$m^{1/2}}
  
  UB <- round(sample_mean + {conf_z_value*sample_sd},2)
  LB <- round(sample_mean - {conf_z_value*sample_sd},2)
  
  return(data.frame(UB, LB, "point_estimate" = sample_mean))
  
}
```

```{r}
# In Bartlett study, B = 200 
seed <- as.vector(rnorm(length(uncon_imputed_data_frames), 0, 1)^2) 
times <- rep(5, length(uncon_imputed_data_frames))

results_mi_boot_rubin_uncon <- c()

for(i in 1:length(uncon_imputed_data_frames)){
  results_mi_boot_rubin_uncon[[i]] <- 
    mi_boot_rubin(uncon_imputed_data_frames[[i]], seed[[i]], times[[i]])
}

results_mi_boot_rubin_con <- c()

pb <- txtProgressBar(min = 0,      
                     max = length(data_frames), 
                     style = 3,    
                     width = 50,   
                     char = "=")  

for(i in 1:length(con_imputed_data_frames)){
  results_mi_boot_rubin_con[[i]] <- 
    mi_boot_rubin(con_imputed_data_frames[[i]], seed[[i]], times[[i]])
  setTxtProgressBar(pb, i)
}
close(pb)
```

# MI boot Pooled Percentile 
```{r}
mi_boot_pooled_percentile <- function(uncon_imp_data, seed, times){
  
  set.seed(seed)
  times = times # Number of bootstrap samples per m. 
  
  bootstrap_samples <- map(
    uncon_imp_data %>%
      complete(., "long") %>%
      group_split(.imp),
    ~ bootstraps(.,
                 times = times,
                 apparent = FALSE) %>%
      mutate(
        model = map(splits, ~ lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = .)),
        coef_inf = map(model, tidy)
      )
  )
  
  sample_size <- nrow(complete(uncon_imp_data, 1))
  
  # Function to obtain the statistics associated with term==V2, and calculate var.  
  coef_extractor <- function(x){
    model_coefs <- x %>%
      unnest(coef_inf) %>%
      filter(term == "V2") %>%
      dplyr::mutate(variance = {std.error*{sample_size^{1/2}}}^2)
    
    return(model_coefs)
  }
  
  # Obtains statistics associated with term == V2 
  model_coefs <- map(bootstrap_samples, coef_extractor)
  
  # Flattens list and gets ordered vector of variances across all MB datasets. 
  var_est_vec_combined <- do.call("rbind", model_coefs) %>%
    dplyr::select(variance) %>%
    arrange(variance) %>%
    unlist() %>%
    as.vector()
  
  # Obtains point estimate of var(Beta*V2), which is the mean across M 
  var_point_estimate <- c()
  for(i in 1:uncon_imp_data$m){
    var_point_estimate[[i]] <- complete(uncon_imp_data, i) %>%
      lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = .) %>%
      summary() %>%
      broom::tidy() %>%
      dplyr::filter(term == "V2") %>%
      dplyr::mutate(variance = {std.error*{sample_size^{1/2}}}^2) %>%
      dplyr::select(variance)
  }
  
  
  # Obtains desired quantiles of var_ests  
  # Using alpha = 0.05 
  quantile(var_est_vec_combined, probs = 0.05)
  quantile(var_est_vec_combined, probs = 1-0.05)
  
  UB <- round(quantile(var_est_vec_combined, probs = 1-0.05),2)
  LB <- round(quantile(var_est_vec_combined, probs = 0.05),2)
  
  return(data.frame(UB, LB, "point_estimate" =  mean(unlist(var_point_estimate))))
  
}
```

```{r}
seed <- as.vector(rnorm(length(uncon_imputed_data_frames), 0, 1)^2) 
times <- rep(5, length(uncon_imputed_data_frames))

results_mi_boot_pooled_percentile_uncon <- c()

for(i in 1:length(uncon_imputed_data_frames)){
  results_mi_boot_pooled_percentile_uncon[[i]] <- 
    mi_boot_rubin(uncon_imputed_data_frames[[i]], seed[[i]], times[[i]])
}

results_mi_boot_pooled_percentile_con <- c()

for(i in 1:length(con_imputed_data_frames)){
  results_mi_boot_pooled_percentile_con[[i]] <- 
    mi_boot_rubin(con_imputed_data_frames[[i]], seed[[i]], times[[i]])
}
```

# Boot MI percentile 
```{r}
boot_mi_percentile <- function(data_w_missing, seed, times){
  
  set.seed(seed)
  times = times # Number of bootstrap samples per m. 
  
  # 1) B bootstraps are generated from the observed data. 
  # 2) Each of the b=1...B datasets are imputed M times. 
  # 3) Rubin's rules are used to obtain point estimates of theta
  # 4) Bootstrap confidence interval of the estimator is obtained
  
  # Bootstraps then imputed data 
  boot_impute <- bootMice(data_w_missing, nBoot = times, nImp = 5, nCores = 4, seed = seed)
  
  # Applies analysis model to each of the b=1,..., B & m=1,..., M dfs. 
  summary_of_analysis <- map(boot_impute, ~broom::tidy(lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = .)))
  
  # Filters results and calculates variance 
  res <- c()
  sample_size <- nrow(data_w_missing)
  for(i in 1:length(summary_of_analysis)){
    res[[i]] <- summary_of_analysis[[i]] %>%
      dplyr::filter(term=="V2") %>%
      dplyr::mutate(variance = {std.error*{sample_size^{1/2}}}^2)
  }
  
  # Combines all BM results into single list 
  flat_models <- bind_rows(res, .id = "column_label")
  
  # Obtains point estimate of variance, which is the mean across BM
  var_point_estimate <- flat_models %>%
    dplyr::select(variance) %>%
    unlist() %>%
    mean()
  
  
  # Gets ordered vector of variances across all MB datasets.
  var_est_vec_combined <- flat_models %>%
    dplyr::select(variance) %>%
    arrange(variance) %>%
    unlist() %>%
    as.vector()
  
  
  # Obtains desired quantiles of var_ests  
  # Using alpha = 0.05 
  quantile(var_est_vec_combined, probs = 0.05)
  quantile(var_est_vec_combined, probs = 1-0.05)
  
  UB <- round(quantile(var_est_vec_combined, probs = 1-0.05),2)
  LB <- round(quantile(var_est_vec_combined, probs = 0.05),2)
  
  return(data.frame(UB, LB, var_point_estimate))
  
}

boot_mi_percentile_congenial <- function(boot_impute){
  
  # 1) B bootstraps are generated from the observed data. 
  # 2) Each of the b=1...B datasets are imputed M times. 
  # 3) Rubin's rules are used to obtain point estimates of theta
  # 4) Bootstrap confidence interval of the estimator is obtained
  
  
  # Applies analysis model to each of the b=1,..., B & m=1,..., M dfs. 
  summary_of_analysis <- map(boot_impute, ~broom::tidy(lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = .)))
  
  # Filters results and calculates variance 
  res <- c()
  sample_size <- nrow(boot_impute[[1]])
  for(i in 1:length(summary_of_analysis)){
    res[[i]] <- summary_of_analysis[[i]] %>%
      dplyr::filter(term=="V2") %>%
      dplyr::mutate(variance = {std.error*{sample_size^{1/2}}}^2)
  }
  
  # Combines all BM results into single list 
  flat_models <- bind_rows(res, .id = "column_label")
  
  # Obtains point estimate of variance, which is the mean across BM
  var_point_estimate <- flat_models %>%
    dplyr::select(variance) %>%
    unlist() %>%
    mean()
  
  
  # Gets ordered vector of variances across all MB datasets.
  var_est_vec_combined <- flat_models %>%
    dplyr::select(variance) %>%
    arrange(variance) %>%
    unlist() %>%
    as.vector()
  
  
  # Obtains desired quantiles of var_ests  
  # Using alpha = 0.05 
  quantile(var_est_vec_combined, probs = 0.05)
  quantile(var_est_vec_combined, probs = 1-0.05)
  
  UB <- round(quantile(var_est_vec_combined, probs = 1-0.05),2)
  LB <- round(quantile(var_est_vec_combined, probs = 0.05),2)
  
  return(data.frame(UB, LB, var_point_estimate))
  
}
```

```{r}
seed <- as.vector(rnorm(length(uncon_imputed_data_frames), 0, 1)^2) 
times <- rep(5, length(uncon_imputed_data_frames))

# Uncongenial can run as is, since we want it to ignore the interaction term. 
results_boot_mi_percentile_uncon <- c()

for(i in 1:length(data_frames)){
  results_boot_mi_percentile_uncon[[i]] <- 
    boot_mi_percentile(data_frames[[i]], seed[[i]], times[[i]])
}

# Congenial needs to take place in two phases to accomodate the interaction term. 

# Impute only V3 == 0
imputed_dfs_part_one <- c()

for(i in 1:length(data_frames)){
 imputed_dfs_part_one[[i]] <- bootMice(data_frames[[i]] %>%
                          dplyr::filter(V3 == "0"), nBoot = times[[i]], nImp = 5, nCores = 8, seed = seed[[i]])
}

plan(multisession, workers = parallel::detectCores())
filtered <- future_map(data_frames, ~dplyr::filter(.x,, V3 == "1")) 

# Impute only V3 ==1
imputed_dfs_part_two <- c()
pb <- txtProgressBar(min = 0,      
                     max = length(data_frames), 
                     style = 3,    
                     width = 50,   
                     char = "=")  

for(i in 1:length(filtered)){
  imputed_dfs_part_two[[i]] <- bootMice(filtered[[i]], nBoot = times[[i]], nImp = 5, nCores = 8, seed = seed[[i]], print = FALSE);
  setTxtProgressBar(pb, i)
}
close(pb)

# rbind the two phases 

combined_imputed_dfs <- vector("list", length = length(data_frames))

for(i in 1:length(data_frames)){
  for(z in 1:40){
    combined_imputed_dfs[[i]][[z]] <- rbind(imputed_dfs_part_one[[i]][[z]], imputed_dfs_part_two[[i]][[z]])
  }
}

plan(multisession, workers = parallel::detectCores())
results_boot_mi_percentile_con <- future_map(combined_imputed_dfs, boot_mi_percentile_congenial)
```


# Organization of Results 
```{r, eval=FALSE}
new_names <- c("UB", "LB", "variance")

rubin_uncongenial_results_final <- lapply(rubin_uncongenial_results_final, setNames, new_names)
rubin_congenial_results_final <- lapply(rubin_congenial_results_final, setNames, new_names)

results_mi_boot_rubin_uncon <- lapply(results_mi_boot_rubin_uncon, setNames, new_names)
results_mi_boot_rubin_con <- lapply(results_mi_boot_rubin_con, setNames, new_names)

results_mi_boot_pooled_percentile_uncon <- lapply(results_mi_boot_pooled_percentile_uncon, setNames, new_names)
results_mi_boot_pooled_percentile_con <- lapply(results_mi_boot_pooled_percentile_con, setNames, new_names)

results_boot_mi_percentile_uncon <- lapply(results_boot_mi_percentile_uncon, setNames, new_names)
results_boot_mi_percentile_con <- lapply(results_boot_mi_percentile_con, setNames, new_names)

shiny_list_data <- list(rubin_uncongenial_results_final, 
                     rubin_congenial_results_final, 
                     results_mi_boot_rubin_uncon, 
                     results_mi_boot_rubin_con, 
                     results_mi_boot_pooled_percentile_uncon, 
                     results_mi_boot_pooled_percentile_con, 
                     results_boot_mi_percentile_uncon, 
                     results_boot_mi_percentile_con)

p <- imap(.x = rubin_uncongenial_results_final, .f = ~transform(.x, method = "rubin", type = "uncongenial", "n" = sample_size_vec[[.x]], p_mis = p_mis_vec[[.x]]))
```   


```{r}
appending_foo <- function(list_of_results, method, type){
  temp_list <- c()
  for(i in 1:999){
    temp_list[[i]] <- 
      transform(list_of_results[[i]], method = method, type = type, "n" = sample_size_vec_repeated[[i]], p_mis = p_mis_vec[[i]])
  }
  temp_df <- do.call(rbind.data.frame, temp_list)
  return(temp_df)
}

rubin_uncongenial <- appending_foo(rubin_uncongenial_results_final, "rubin", "uncongenial")
rubin_congenial <- appending_foo(rubin_congenial_results_final, "rubin", "congenial")

mi_boot_rubin_uncongenial <- appending_foo(results_mi_boot_rubin_uncon, "mi_boot_rubin", "uncongenial")
mi_boot_rubin_congenial <- appending_foo(results_mi_boot_rubin_con, "mi_boot_rubin", "congenial")

mi_boot_rubin_pooled_uncongenial <- appending_foo(results_mi_boot_pooled_percentile_uncon, "mi_boot_rubin_pooled", "uncongenial")
mi_boot_rubin_pooled_congenial <- appending_foo(results_mi_boot_pooled_percentile_con, "mi_boot_rubin_pooled", "congenial")      

boot_mi_pooled_uncongenial <- appending_foo(results_boot_mi_percentile_uncon, "boot_mi_pooled", "uncongenial")   
boot_mi_pooled_congenial <- appending_foo(results_boot_mi_percentile_con, "boot_mi_pooled", "congenial")   


final_results_df <- rbind(rubin_uncongenial, 
                      rubin_congenial, 
                      mi_boot_rubin_uncongenial, 
                      mi_boot_rubin_congenial, 
                      mi_boot_rubin_pooled_uncongenial, 
                      mi_boot_rubin_pooled_congenial, 
                      boot_mi_pooled_uncongenial, 
                      boot_mi_pooled_congenial)

write_csv(final_results_df, file = "final_sim_results.csv")
```


# Visual for results 
```{r, eval=FALSE}
ci_plots <- function(data_set, x){
  df <- data_set %>%
    do.call(rbind.data.frame, .); 
  
  ggplot(df, aes(x = x, y = variance)) + 
           geom_point() + 
           geom_errorbar(aes(ymin = LB, ymax = UB)) + 
           coord_flip() + 
           theme_classic() + 
    labs(
      x = TeX("$i^{th} dataset"), 
      y = TeX("$\\sigma^2")
    )
} 


ci_plots(shiny_list_data[[5]][889:999], c(1:111))
```

