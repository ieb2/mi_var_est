---
title: "main_doc"
author: "Ihsan E. Buker"
date: "`r Sys.Date()`"
output: html_document
---
# Updates 
  
  * Had to change sizes: 
    * N = 333 vs. 999 
    * B = 5 vs. 200 
    * m = 5 vs. 10 
    * itr = 5 vs. ~25
  * Problem with rlang on server but think I got it figured out. 
  * Need to organize data
    * Combine point estimates and CIs 
    * Literature focuses on CI comparison 
  * Random question
    * 
# Dependencies 
```{r}
library(tidyverse)
library(magrittr)
library(mice)
library(MASS)
library(sjPlot) # Used for interaction visual 
library(sjmisc) # Used for interaction visual 
library(ggplot2) # Used for interaction visual 
library(furrr) # To use parallel "purrr" functions
library(progressr) # For progress bar on furrr 

library(rsample)
library(bootImpute) # For boot_mi_percentile 
```

# Data Generation 
```{r, cache=TRUE}
data_generator <- function(sample_size, prop, seed){
  set.seed(seed)
  cor_mat <- matrix(c(1, 0.5, 0.5, 
                      0.5, 1, 0.5, 
                      0.5, 0.5, 1), nrow = 3, ncol = 3)
  
  mean_vec <- c(1, 1, 1)
  
  covariates <- as.data.frame(mvrnorm(sample_size, mu = mean_vec, Sigma = cor_mat))
  covariates$V3 <- ifelse(covariates$V3 > 0, 1, 0)
  
  outcome_variable <- 0 + 
    0.32*covariates$V1 + 
    0.67*covariates$V2 +  
    0.43*covariates$V3 + 
    0.50*covariates$V2*covariates$V3 + # Interaction btwn. V2&V3
    rnorm(100,0,1)
  
  data_complete <- cbind(outcome_variable, covariates)
  data_complete$V3 <- as.factor(data_complete$V3)
  
  data_w_missing <- ampute(data_complete, prop = prop, mech = "MAR", patterns = c(0, 1, 1, 1))$amp
  
  data_w_missing$V3 <- as.factor(ifelse(data_w_missing$V3 == 1, 0, 1))
  
  # "outcome_variable" is an outcome variable with 30% MAR. Covariates are fully observed. 
  
  # The analysis model is outcome_variable ~ V1 + V2 + V3 + V2*V3 + epsilon 
  # We are interested in estimating var(beta*V2)
  
  return(data_w_missing)
}

# The influence of V2 on outcome var is different for values of V3
# Two-way interaction btwn. V2*V3. 
```

# Imputation of data
```{r, eval=FALSE}
# Congenial imputation 
# To accomodate interaction V3 == 0 and V3 == 1 are imputed independently and combined. See van Buuren "Derived Vars" 

part_one_con_imp <- 
  data_w_missing %>% 
  dplyr::filter(V3 == "0") %>%
  mice(., method = "pmm")

part_two_con_imp <- 
  data_w_missing %>% 
  dplyr::filter(V3 == "1") %>%
  mice(., method = "pmm")

con_imp <- mice::rbind(part_one_con_imp, part_two_con_imp) 
con_imp_data <- complete(con_imp, "long")

# Uncongenal imputation 
# Ignores interaction between V2:V3, uncongenial to analysis model which does not ignore interaction. 
uncon_imp <- mice(data_w_missing, method = "pmm")
uncon_imp_data <- complete(uncon_imp, "long")
```

# Full data analysis 
```{r, eval = FALSE}
# Fitting analysis model 
lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = data_complete) %>% 
  summary() %>%
  broom::tidy() %>%
  dplyr::filter(term == "V2") %>%
  dplyr::mutate(variance = {std.error*{sample_size^{1/2}}}^2)
```


# Simulation Setup 
* N = 999 datasets 
* p_mis $\in$ {0.10, 0.30, 0.50}
* Mechanism of Missingness = MAR 
* n = sample size $\in$ {500, 1000, 10000}
* q = number of covariates = 3 
* Interaction between Var2 and Var3 
```{r, warning=F, cache=TRUE}
set.seed(971423)
N = 333 
p_mis_vec <- c(rep(0.10, N), rep(0.30, N), rep(0.50, N))
sample_size_vec <- c(rep(500, N/3), rep(1000, N/3), rep(10000, N/3))
seed_vec <- rnorm(N, 0, 1)^2

sample_size_vec_repeated <- rep.int(sample_size_vec, 3)

param_df <- data.frame(sample_size = sample_size_vec_repeated, prop = p_mis_vec, seed = seed_vec)

data_frames <- do.call(Map, c(f=data_generator, param_df))

# Uncongenial Imputation of data frames w/ missing outcome_vars 
plan(multisession, workers = parallel::detectCores()-1)

with_progress({
  p <- progressor(steps = length(data_frames))
  
  uncon_imputed_data_frames <- future_map(data_frames, ~{
    p(); 
    mice(data = .x, method = "pmm", print=FALSE)
  }, p = p)
})

part_one_con_imp <-
  purrr::map(data_frames, ~ dplyr::filter(., V3 == "0"))

part_one_imputed <- lapply(part_one_con_imp, function(x) mice(x, method = "pmm", print = FALSE)) 

part_two_con_imp <-
  purrr::map(data_frames, ~ dplyr::filter(., V3 == "1"))

part_two_imputed <- lapply(part_two_con_imp, function(x) mice(x, method = "pmm", print = FALSE)) 



con_imputed_data_frames <- c()
for(i in 1:length(part_two_imputed)){
  con_imputed_data_frames[[i]] <- mice::rbind(part_one_imputed[[i]], part_two_imputed[[i]]) 
}
```

# Rubin's rules 
```{r}
rubin_results_uncongenial <- c()
for(i in 1:length(uncon_imputed_data_frames)){
  sample_size <- nrow(complete(uncon_imputed_data_frames[[i]],1))
  rubin_results_uncongenial[[i]] <- uncon_imputed_data_frames[[i]] %>%
    complete(., "long") %>%
    by(as.factor(.$.imp), lm, formula = outcome_variable ~ V1 + V2 + V3 +  V2*V3) %>%
    pool() %>%
    summary() %>%
    dplyr::mutate(variance = {std.error*{sample_size^{1/2}}}^2)
}

rubin_results_congenial <- c()

for(i in 1:length(con_imputed_data_frames)){
 sample_size <- nrow(complete(con_imputed_data_frames[[i]],1))
  rubin_results_congenial[[i]] <- try(con_imputed_data_frames[[i]] %>%
    complete(., "long") %>%
    by(as.factor(.$.imp), lm, formula = outcome_variable ~ V1 + V2 + V3 +  V2*V3) %>%
    pool() %>%
    summary() %>%
    dplyr::mutate(variance = {std.error*{sample_size^{1/2}}}^2))
}
```

# MI boot Rubin 
```{r}
mi_boot_rubin <- function(uncon_imp_data, seed, times){
  
  set.seed(seed)
  times = times # Number of bootstrap samples per m. 
  
  bootstrap_samples <- map(
    uncon_imp_data %>%
      complete(., "long") %>%
      group_split(.imp),
    ~ bootstraps(.,
                 times = times,
                 apparent = FALSE) %>%
      mutate(
        model = map(splits, ~ lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = .)),
        coef_inf = map(model, tidy)
      )
  )
  
  sample_size <- nrow(complete(uncon_imp_data, 1))
  
  # Function to obtain the statistics associated with term==V2, and calculate var.  
  coef_extractor <- function(x){
    model_coefs <- x %>%
      unnest(coef_inf) %>%
      filter(term == "V2") %>%
      dplyr::mutate(variance = {std.error*{sample_size^{1/2}}}^2)
    
    return(model_coefs)
  }
  
  # Obtains statistics associated with term == V2 
  model_coefs <- map(bootstrap_samples, coef_extractor)
  
  # Calculates mean var(Beta*V2) for m^th dataset. 
  m_mean_vars <- sapply(model_coefs, function(x) mean(x$variance)) 
  
  # Combines statistics w/ mean var(Beta*V2) of m^th dataset. 
  model_coefs_w_mean <- mapply(cbind, model_coefs, "m_mean_var" = m_mean_vars, SIMPLIFY = F)
  
  # Function to calculate the squared difference between m^th mean_var
  # and b^th var.  
  dif_calc <- function(x){
    x %>%
      dplyr::mutate("internal_argument" = ({variance - m_mean_vars})^2)
  }
  
  # Combines squared variance difference with rest of statistics. 
  model_coefs_w_ia <- map(model_coefs_w_mean, dif_calc)
  
  # Function to estimate within-imputation variance
  w_i_var_estimator <- function(x){
    data <- x$internal_argument
    var_est <- sum(data)/{times-1}
  }
  
  # Obtains M estimates of var(beta*V2) in list (Serves as ~Standard Error)
  var_se_estimate <- lapply(model_coefs_w_ia, w_i_var_estimator)
  
  # M point estimates of var(beta*V2) obtained from imputed but not 
  # bootstrapped data 
  
  var_point_estimate <- c()
  for(i in 1:uncon_imp_data$m){
    var_point_estimate[[i]] <- complete(uncon_imp_data, i) %>%
      lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = .) %>%
      summary() %>%
      broom::tidy() %>%
      dplyr::filter(term == "V2") %>%
      dplyr::mutate(variance = {std.error*{sample_size^{1/2}}}^2) %>%
      dplyr::select(variance)
  }
  
  sample_mean <- mean(as.data.frame(unlist(var_point_estimate))$"unlist(var_point_estimate)")
  conf_z_value <- 1.96 
  sample_sd <- mean({unlist(var_se_estimate)^{1/2}})/{uncon_imp_data$m^{1/2}}
  
  UB <- round(sample_mean + {conf_z_value*sample_sd},2)
  LB <- round(sample_mean - {conf_z_value*sample_sd},2)
  
  return(data.frame(UB, LB, "point_estimate" = sample_mean))
  
}
```

```{r}
# In Bartlett study, B = 200 
seed <- as.vector(rnorm(length(uncon_imputed_data_frames), 0, 1)^2) 
times <- rep(5, length(uncon_imputed_data_frames))

results_mi_boot_rubin_uncon <- c()

for(i in 1:length(uncon_imputed_data_frames)){
  results_mi_boot_rubin_uncon[[i]] <- 
    mi_boot_rubin(uncon_imputed_data_frames[[i]], seed[[i]], times[[i]])
}

results_mi_boot_rubin_con <- c()

for(i in 1:length(con_imputed_data_frames)){
  results_mi_boot_rubin_con[[i]] <- 
    mi_boot_rubin(con_imputed_data_frames[[i]], seed[[i]], times[[i]])
}
```

# MI boot Pooled Percentile 
```{r}
mi_boot_pooled_percentile <- function(uncon_imp_data, seed, times){
  
  set.seed(seed)
  times = times # Number of bootstrap samples per m. 
  
  bootstrap_samples <- map(
    uncon_imp_data %>%
      complete(., "long") %>%
      group_split(.imp),
    ~ bootstraps(.,
                 times = times,
                 apparent = FALSE) %>%
      mutate(
        model = map(splits, ~ lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = .)),
        coef_inf = map(model, tidy)
      )
  )
  
  sample_size <- nrow(complete(uncon_imp_data, 1))
  
  # Function to obtain the statistics associated with term==V2, and calculate var.  
  coef_extractor <- function(x){
    model_coefs <- x %>%
      unnest(coef_inf) %>%
      filter(term == "V2") %>%
      dplyr::mutate(variance = {std.error*{sample_size^{1/2}}}^2)
    
    return(model_coefs)
  }
  
  # Obtains statistics associated with term == V2 
  model_coefs <- map(bootstrap_samples, coef_extractor)
  
  # Flattens list and gets ordered vector of variances across all MB datasets. 
  var_est_vec_combined <- do.call("rbind", model_coefs) %>%
    dplyr::select(variance) %>%
    arrange(variance) %>%
    unlist() %>%
    as.vector()
  
  # Obtains point estimate of var(Beta*V2), which is the mean across M 
  var_point_estimate <- c()
  for(i in 1:uncon_imp_data$m){
    var_point_estimate[[i]] <- complete(uncon_imp_data, i) %>%
      lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = .) %>%
      summary() %>%
      broom::tidy() %>%
      dplyr::filter(term == "V2") %>%
      dplyr::mutate(variance = {std.error*{sample_size^{1/2}}}^2) %>%
      dplyr::select(variance)
  }
  
  
  # Obtains desired quantiles of var_ests  
  # Using alpha = 0.05 
  quantile(var_est_vec_combined, probs = 0.05)
  quantile(var_est_vec_combined, probs = 1-0.05)
  
  UB <- round(quantile(var_est_vec_combined, probs = 1-0.05),2)
  LB <- round(quantile(var_est_vec_combined, probs = 0.05),2)
  
  return(data.frame(UB, LB, "point_estimate" =  mean(unlist(var_point_estimate))))
  
}
```

```{r}
seed <- as.vector(rnorm(length(uncon_imputed_data_frames), 0, 1)^2) 
times <- rep(5, length(uncon_imputed_data_frames))

results_mi_boot_pooled_percentile_uncon <- c()

for(i in 1:length(uncon_imputed_data_frames)){
  results_mi_boot_pooled_percentile_uncon[[i]] <- 
    mi_boot_rubin(uncon_imputed_data_frames[[i]], seed[[i]], times[[i]])
}

results_mi_boot_pooled_percentile_con <- c()

for(i in 1:length(con_imputed_data_frames)){
  results_mi_boot_pooled_percentile_con[[i]] <- 
    mi_boot_rubin(con_imputed_data_frames[[i]], seed[[i]], times[[i]])
}
```

# Boot MI percentile 
```{r}
boot_mi_percentile <- function(data_w_missing, seed, times){
  
  set.seed(seed)
  times = times # Number of bootstrap samples per m. 
  
  # 1) B bootstraps are generated from the observed data. 
  # 2) Each of the b=1...B datasets are imputed M times. 
  # 3) Rubin's rules are used to obtain point estimates of theta
  # 4) Bootstrap confidence interval of the estimator is obtained
  
  # Bootstraps then imputed data 
  boot_impute <- bootMice(data_w_missing, nBoot = times, nImp = 5, nCores = 4, seed = seed)
  
  # Applies analysis model to each of the b=1,..., B & m=1,..., M dfs. 
  summary_of_analysis <- map(boot_impute, ~tidy(lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = .)))
  
  # Filters results and calculates variance 
  res <- c()
  sample_size <- nrow(data_w_missing)
  for(i in 1:length(summary_of_analysis)){
    res[[i]] <- summary_of_analysis[[i]] %>%
      dplyr::filter(term=="V2") %>%
      dplyr::mutate(variance = {std.error*{sample_size^{1/2}}}^2)
  }
  
  # Combines all BM results into single list 
  flat_models <- bind_rows(res, .id = "column_label")
  
  # Obtains point estimate of variance, which is the mean across BM
  var_point_estimate <- flat_models %>%
    dplyr::select(variance) %>%
    unlist() %>%
    mean()
  
  
  # Gets ordered vector of variances across all MB datasets.
  var_est_vec_combined <- flat_models %>%
    dplyr::select(variance) %>%
    arrange(variance) %>%
    unlist() %>%
    as.vector()
  
  
  # Obtains desired quantiles of var_ests  
  # Using alpha = 0.05 
  quantile(var_est_vec_combined, probs = 0.05)
  quantile(var_est_vec_combined, probs = 1-0.05)
  
  UB <- round(quantile(var_est_vec_combined, probs = 1-0.05),2)
  LB <- round(quantile(var_est_vec_combined, probs = 0.05),2)
  
  return(data.frame(UB, LB, var_point_estimate))
  
}
```

```{r}
seed <- as.vector(rnorm(length(uncon_imputed_data_frames), 0, 1)^2) 
times <- rep(8, length(uncon_imputed_data_frames))

results_boot_mi_percentile_uncon <- c()

for(i in 1:length(uncon_imputed_data_frames)){
  results_mi_boot_rubin_uncon[[i]] <- 
    mi_boot_pooled_percentile(uncon_imputed_data_frames[[i]], seed[[i]], times[[i]])
}

results_mi_boot_rubin_con <- c()

for(i in 1:length(con_imputed_data_frames)){
  results_mi_boot_rubin_con[[i]] <- 
    mi_boot_pooled_percentile(con_imputed_data_frames[[i]], seed[[i]], times[[i]])
}
```


# Organization of Results 
```{r}
rubin_results_uncongenial %>%
  View()
rubin_results_congenial

results_mi_boot_rubin_uncon
results_mi_boot_rubin_con

results_mi_boot_pooled_percentile_uncon
results_mi_boot_pooled_percentile_con

results_boot_mi_percentile_uncon
results_boot_mi_percentile_con
```


# Visual for results 
```{r, eval=FALSE}
flat_list <- bind_rows(model_coefs_final)

flat_list %>%
  ggplot(aes(
    x = variance,
    y = ..scaled..,
    color = as.factor(SampleID),
    fill = as.factor(SampleID)
  )) +
  geom_density(alpha = .3) +
  ggtitle(paste("Distribution of Estimated Variance of B_{V2}: B =", times, sep = "")) +
  xlab("Estimate") +
  ylab("Frequency") +
  theme_minimal() +
  theme(legend.title = element_blank())
```

