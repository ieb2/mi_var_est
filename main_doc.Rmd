---
title: "main_doc"
author: "Ihsan E. Buker"
date: "`r Sys.Date()`"
output: html_document
---
# Updates 
  * Consider going over Boot MI von Hippel 

# Dependencies 
```{r}
library(tidyverse)
library(magrittr)
library(mice)
library(MASS)
library(sjPlot) # Used for interaction visual 
library(sjmisc) # Used for interaction visual 
library(ggplot2) # Used for interaction visual 

library(rsample)
library(bootImpute) # For boot_mi_percential 
```



# Data Generation 
```{r, cache=T}
set.seed(971423)
sample_size <- 100 

cor_mat <- matrix(c(1, 0.5, 0.5, 
                    0.5, 1, 0.5, 
                    0.5, 0.5, 1), nrow = 3, ncol = 3)

mean_vec <- c(1, 1, 1)

covariates <- as.data.frame(mvrnorm(sample_size, mu = mean_vec, Sigma = cor_mat))
covariates$V3 <- ifelse(covariates$V3 > 0, 1, 0)

outcome_variable <- 0 + 
  0.32*covariates$V1 + 
  0.67*covariates$V2 +  
  0.43*covariates$V3 + 
  0.50*covariates$V2*covariates$V3 + # Interaction btwn. V2&V3
  rnorm(100,0,1)

data_complete <- cbind(outcome_variable, covariates)
data_complete$V3 <- as.factor(data_complete$V3)

fit <- lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = data_complete)
summary(fit)

# The influence of V2 on outcome var is different for values of V3
# Two-way interaction btwn. V2*V3. 
plot_model(fit, type = "int")

data_w_missing <- ampute(data_complete, prop = 0.3, mech = "MAR", patterns = c(0, 1, 1, 1))$amp

data_w_missing$V3 <- as.factor(ifelse(data_w_missing$V3 == 1, 0, 1))

# "outcome_variable" is an outcome variable with 30% MAR. Covariates are fully observed. 

# The analysis model is outcome_variable ~ V1 + V2 + V3 + V2*V3 + epsilon 
# We are interested in estimating var(beta*V2)
```



# Imputation of data 
```{r}
# Congenial imputation 
# To accomodate interaction V3 == 0 and V3 == 1 are imputed independently and combined. See van Buuren "Derived Vars"  
part_one_con_imp <- 
  data_w_missing %>% 
  dplyr::filter(V3 == "0") %>%
  mice(., method = "pmm")

part_two_con_imp <- 
  data_w_missing %>% 
  dplyr::filter(V3 == "1") %>%
  mice(., method = "pmm")

con_imp_data <- rbind(
  complete(part_one_con_imp, "long"),
  complete(part_two_con_imp, "long")
)
# Uncongenial imputation 
# Ignores interaction between V2:V3, uncongenial to analysis model which does not ignore interaction. 
uncon_imp <- mice(data_w_missing, method = "pmm")

uncon_imp_data <- complete(uncon_imp, "long")
```


# Full data analysis 
```{r}
# Fitting analysis model 
# var(beta*V2) = 5.119662
lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = data_complete) %>%
  summary() %>%
  broom::tidy() %>%
  dplyr::filter(term == "V2") %>%
  mutate(variance = {std.error*{sample_size^{1/2}}}^2)
```

# Rubin's rules 
```{r}
# var(beta*V2) = 5.059615 -> Our reference value. 
con_imp_data %>%
  by(as.factor(.$.imp), lm, formula = outcome_variable ~ V1 + V2 + V3 +  V2*V3) %>%
  pool() %>%
  summary() %>%
  mutate(variance = {std.error*{sample_size^{1/2}}}^2) 

# var(beta*V2) = 5.373042
uncon_imp_data %>%
  by(as.factor(.$.imp), lm, formula = outcome_variable ~ V1 + V2 + V3 +  V2*V3) %>%
  pool() %>%
  summary() %>%
  mutate(variance = {std.error*{sample_size^{1/2}}}^2)
```



# MI boot Rubin 
```{r}
mi_boot_rubin <- function(seed, times){
  
  set.seed(seed)
  times = times # Number of bootstrap samples per m. 
  
  bootstrap_samples <- map(
    uncon_imp_data %>%
      group_split(.imp),
    ~ bootstraps(.,
                 times = times,
                 apparent = FALSE) %>%
      mutate(
        model = map(splits, ~ lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = .)),
        coef_inf = map(model, tidy)
      )
  )
  
  
  # Function to obtain the statistics associated with term==V2, and calculate var.  
  coef_extractor <- function(x){
    model_coefs <- x %>%
      unnest(coef_inf) %>%
      filter(term == "V2") %>%
      mutate(variance = {std.error*{sample_size^{1/2}}}^2)
    
    return(model_coefs)
  }
  
  # Obtains statistics associated with term == V2 
  model_coefs <- map(bootstrap_samples, coef_extractor)
  
  # Calculates mean var(Beta*V2) for m^th dataset. 
  m_mean_vars <- sapply(model_coefs, function(x) mean(x$variance)) 
  
  # Combines statistics w/ mean var(Beta*V2) of m^th dataset. 
  model_coefs_w_mean <- mapply(cbind, model_coefs, "m_mean_var" = m_mean_vars, SIMPLIFY = F)
  
  # Function to calculate the squared difference between m^th mean_var
  # and b^th var.  
  dif_calc <- function(x){
    x %>%
      dplyr::mutate("internal_argument" = ({variance - m_mean_vars})^2)
  }
  
  # Combines squared variance difference with rest of statistics. 
  model_coefs_w_ia <- map(model_coefs_w_mean, dif_calc)
  
  # Function to estimate within-imputation variance
  w_i_var_estimator <- function(x){
    data <- x$internal_argument
    var_est <- sum(data)/{times-1}
  }
  
  # Obtains M estimates of var(beta*V2) in list (Serves as ~Standard Error)
  var_se_estimate <- lapply(model_coefs_w_ia, w_i_var_estimator)
  
  # M point estimates of var(beta*V2) obtained from imputed but not 
  # bootstrapped data 
  
  var_point_estimate <- c()
  for(i in 1:uncon_imp$m){
    var_point_estimate[[i]] <- complete(uncon_imp, i) %>%
      lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = .) %>%
      summary() %>%
      broom::tidy() %>%
      dplyr::filter(term == "V2") %>%
      mutate(variance = {std.error*{sample_size^{1/2}}}^2) %>%
      dplyr::select(variance)
  }
  
  sample_mean <- mean(as.data.frame(unlist(var_point_estimate))$"unlist(var_point_estimate)")
  conf_z_value <- 1.96 
  sample_sd <- mean({unlist(var_se_estimate)^{1/2}})/{uncon_imp$m^{1/2}}
  
  UB <- round(sample_mean + {conf_z_value*sample_sd},2)
  LB <- round(sample_mean - {conf_z_value*sample_sd},2)
  
  return(paste(LB, UB, sep = ",")) 
  
}
```


# MI boot Pooled Percentile 
```{r}
mi_boot_pooled_percentile <- function(seed, times){
  
  set.seed(seed)
  times = times # Number of bootstrap samples per m. 
  
  bootstrap_samples <- map(
    uncon_imp_data %>%
      group_split(.imp),
    ~ bootstraps(.,
                 times = times,
                 apparent = FALSE) %>%
      mutate(
        model = map(splits, ~ lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = .)),
        coef_inf = map(model, tidy)
      )
  )
  
  
  # Function to obtain the statistics associated with term==V2, and calculate var.  
  coef_extractor <- function(x){
    model_coefs <- x %>%
      unnest(coef_inf) %>%
      filter(term == "V2") %>%
      mutate(variance = {std.error*{sample_size^{1/2}}}^2)
    
    return(model_coefs)
  }
  
  # Obtains statistics associated with term == V2 
  model_coefs <- map(bootstrap_samples, coef_extractor)
  
  # Flattens list and gets ordered vector of variances across all MB datasets. 
  var_est_vec_combined <- do.call("rbind", model_coefs) %>%
    dplyr::select(variance) %>%
    arrange(variance) %>%
    unlist() %>%
    as.vector()
  
  # Obtains point estimate of var(Beta*V2), which is the mean across M 
  var_point_estimate <- c()
  for(i in 1:uncon_imp$m){
    var_point_estimate[[i]] <- complete(uncon_imp, i) %>%
      lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = .) %>%
      summary() %>%
      broom::tidy() %>%
      dplyr::filter(term == "V2") %>%
      mutate(variance = {std.error*{sample_size^{1/2}}}^2) %>%
      dplyr::select(variance)
  }
  
  mean(unlist(var_point_estimate))
  
  # Obtains desired quantiles of var_ests  
  # Using alpha = 0.05 
  quantile(var_est_vec_combined, probs = 0.05)
  quantile(var_est_vec_combined, probs = 1-0.05)
  
  UB <- round(quantile(var_est_vec_combined, probs = 1-0.05),2)
  LB <- round(quantile(var_est_vec_combined, probs = 0.05),2)
  
  return(paste(LB, UB, sep = ",")) 
  
}
```

# Boot MI percentile 
```{r}
boot_mi_percentile <- function(seed, times){
  
  set.seed(seed)
  times = times # Number of bootstrap samples per m. 
  
  # 1) B bootstraps are generated from the observed data. 
  # 2) Each of the b=1...B datasets are imputed M times. 
  # 3) Rubin's rules are used to obtain point estimates of theta
  # 4) Bootstrap confidence interval of the estimator is obtained
  
  # Bootstraps then imputed data 
  boot_impute <- bootMice(data_w_missing, nBoot = 100, nImp = 2, nCores = 4, seed = seed)
  
  # Applies analysis model to each of the b=1,..., B & m=1,..., M dfs. 
  summary_of_analysis <- map(boot_impute, ~tidy(lm(outcome_variable ~ V1 + V2 + V3 + V2*V3, data = .)))
  
  # Filters results and calculates variance 
  res <- c()
  
  for(i in 1:length(x)){
    res[[i]] <- summary_of_analysis[[i]] %>%
      dplyr::filter(term=="V2") %>%
      mutate(variance = {std.error*{sample_size^{1/2}}}^2)
  }
  
  # Combines all BM results into single list 
  flat_models <- bind_rows(res, .id = "column_label")
  
  # Obtains point estimate of variance, which is the mean across BM
  flat_models %>%
    dplyr::select(variance) %>%
    unlist() %>%
    mean()
  
  # Gets ordered vector of variances across all MB datasets.
  var_est_vec_combined <- flat_models %>%
    dplyr::select(variance) %>%
    arrange(variance) %>%
    unlist() %>%
    as.vector()
  
  
  # Obtains desired quantiles of var_ests  
  # Using alpha = 0.05 
  quantile(var_est_vec_combined, probs = 0.05)
  quantile(var_est_vec_combined, probs = 1-0.05)
  
  UB <- round(quantile(var_est_vec_combined, probs = 1-0.05),2)
  LB <- round(quantile(var_est_vec_combined, probs = 0.05),2)
  
  return(paste(LB, UB, sep = ",")) 
  
}
```






# Visual for results 
```{r}
flat_list <- bind_rows(model_coefs_final)
  

flat_list %>%
  ggplot(aes(
    x = variance,
    y = ..scaled..,
    color = as.factor(SampleID),
    fill = as.factor(SampleID)
  )) +
  geom_density(alpha = .3) +
  ggtitle(paste("Distribution of Estimated Variance of B_{V2}: B =", times, sep = "")) +
  xlab("Estimate") +
  ylab("Frequency") +
  theme_minimal() +
  theme(legend.title = element_blank())
```


